---
title: "MATCHSUM 논문 리뷰"
date: 2021-07-25 17:14:18 -0400
categories: NLP
tag : Text-Summarization
---

# **MatchSum (Zhong et al., 2020, ACL)**

[📄**Paper : Extractive Summarization as Text Matching**](https://aclanthology.org/2020.acl-main.552/)

<br>


## 💡 **Contribution 정리**


### 1) Summary-Level Framework : **MATCHSUM**  

loss function을 summary-level로 design 
      
<br>
  
$L_{1}$ (*margin-based triplet loss*)   
: 전체 candidate summary $C$와 document $D$간 consine simarity, gold summary $C^{*}$와 $D$ 간 cosine similarity 비교   

$L_{2}$ (*pairwise margin loss*)  
: 각 candidate summary와 gold summary의 ROUGE score를 측정하여 정렬한 후,  
 $i$번째 순위의 candidate summary $C_{i}$와 $j$번째 순위의 $C_{j}$에 대해 candidate pair간 loss 측정
 
 gold summary에 따른 ranking gap ($j-i$)이 크고, $C_{j}$와 $C_{i}$의 document similarity의 차가 클수록 loss 값이 증가한다.  
 
$L_1 = max(0, f(D,C)-f(D,C^{*})+r_1) \newline  L_2 = max(0, f(D,C_{j})-f(D,C_{i})+(j-i)*r_{2}) \newline L=L_{1}+L_{2}
$

<br>

> 각 *candidate summary*는 데이터셋에 따라 2-3문장으로 이루어져 있다. (*not sentence level*)

> Zhong et al.의 실험에서는 BERT-Ext 모델을 통해 Document로부터 5개의 문장 (ROUGE score 상위 5문장)을 추출한 후, 이 5개의 문장으로부터 총 20개의 candidate summary set을 생성하였다 (학습 파라미터인 `candidate_num`을 통해 변경 가능).

<br>

### 2) 각 데이터셋에 따른 inherent gap 분석

데이터셋마다 gap의 크기에 차이가 있음
→ gap이 클수록, Summary-level method가 필수적이며, 작으면 Sentence-level의 method로도 충분함

*(gap : summary-level과 sentence-level method를 각각 적용했을 때 ROUGE score의 차이)*

<br>
<div align=left>
<img src="/assets/images/matchsum/gap.PNG" width=450/><br>
</div>

논문에서는 6개의 데이터 셋을 사용하여 각 데이터셋이 가지는 gap을 측정하였다.  
Short Summary length를 가지는 Reddit, XSum와  
Long length를 가지는 PubMed, Multi-News는 작은 gap을 가졌다.    
Medium length의 CNN/DM이 가장 큰 gap을 가지고, 그 다음으로 Long length의 WikiHow의 gap이 큰 것을 확인하였다.


<br>
<div align=left>
<img src="/assets/images/matchsum/z_distribution.PNG" width=450/><br>
</div>

또한, 각 데이터셋의 Best Summary의 sentence-level scoring에 따른 순위 분포를 제공했다.  
PubMed는 Best Summary가 sentence-level scoring에 따른 순위 상위권에 밀집해 있으며,  
이는 sentence-level로도 충분히 성능을 보일 수 있음을 의미한다.

반면에, WikiHow와 Multi-News는 Best Summary 분포를 보았을 때, sentence-level extraction으로는 Best Summary를 추출하기 어렵다는 것을 알 수 있다.


이로 인한 실험 결과, 각 데이터셋에 MATCHSUM에 따른 성능 개선 정도를 분석하였다.

<br>
<div align=left>
<img src="/assets/images/matchsum/ratio.PNG" width=450/><br>
</div>

PubMed와 Multi-News의 성능 개선 정도가 0.2 이하인 것을 보아, 길이가 긴 Summary에 대해서는 MATCHSUM이 성능이 크게 향상시키지 않음을 알 수 있다.
이 중에서도 Multi-News가 PubMed 보다는 성능향상 젇도가 높은데, 이는 Best Summary의 분포에 따른 것으로 볼 수 있다.
PubMed는 Sentence-level extraction으로도 성능이 좋게 나오기 때문에, MATCHSUM을 통해 개선될 여지가 적다.